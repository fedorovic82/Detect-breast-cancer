#!/usr/bin/env python
# coding: utf-8

# In[1]:


import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')


# In[5]:


get_ipython().run_cell_magic('bash', '', 'pip install seaborn')


# In[6]:


import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')


# In[7]:


df = pd.read_csv("http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data", header=None)
df.head()


# In[8]:


df.columns = ['id', 'Clump Thickness', 'Uniformity of Cell Size', 
       'Uniformity of Cell Shape', 'Marginal Adhesion', 
       'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',
       'Normal Nucleoli', 'Mitoses', 'Class']


# In[9]:


df.head()


# In[10]:


df.shape


# In[11]:


df.info()


# # Data Pre-processing

# In[12]:


df['Bare Nuclei'].describe()


# In[13]:


df['Bare Nuclei'].value_counts()


# In[14]:


df[df['Bare Nuclei'] == "?"]


# In[15]:


df['Class'].value_counts()


# In[16]:


df['Bare Nuclei'].replace("?", np.NAN, inplace=True)
df = df.dropna()


# In[17]:


df['Bare Nuclei'].value_counts()


# In[18]:


df['Class'] = df['Class'] / 2 - 1


# In[19]:


df['Class'].value_counts()


# In[20]:


df.columns


# In[21]:


df.info()


# In[22]:


X = df.drop(['id', 'Class'], axis=1)
X_col = X.columns


# In[23]:


y = df['Class']


# In[24]:


from sklearn.preprocessing import StandardScaler


# In[25]:


X = StandardScaler().fit_transform(X.values)


# In[26]:


from sklearn.model_selection import train_test_split


# In[27]:


df1 = pd.DataFrame(X, columns=X_col)


# In[28]:


df1.head()


# In[29]:


X_train, X_test, y_train, y_test = train_test_split(df1, y,
                                                    train_size=0.8,
                                                    random_state=42)


# In[30]:


from sklearn.preprocessing import MinMaxScaler
pd.DataFrame(MinMaxScaler().fit_transform(df.drop(['id', 'Class'], axis=1).values), columns=X_col).head()


# In[31]:


from sklearn.neighbors import KNeighborsClassifier


# In[32]:


knn = KNeighborsClassifier(n_neighbors=5,
                           p=2, metric='minkowski')


# In[33]:


knn.fit(X_train, y_train)


# In[34]:


from sklearn.model_selection import cross_val_predict, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


# In[35]:


def print_score(clf, X_train, y_train, X_test, y_test, train=True):
    if train:
        print("Train Result:\n")
        print("accuracy score: {0:.4f}\n".format(accuracy_score(y_train, clf.predict(X_train))))
        print("Classification Report: \n {}\n".format(classification_report(y_train, clf.predict(X_train))))
        print("Confusion Matrix: \n {}\n".format(confusion_matrix(y_train, clf.predict(X_train))))

        res = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')
        print("Average Accuracy: \t {0:.4f}".format(np.mean(res)))
        print("Accuracy SD: \t\t {0:.4f}".format(np.std(res)))
        
    elif train==False:
        print("Test Result:\n")        
        print("accuracy score: {0:.4f}\n".format(accuracy_score(y_test, clf.predict(X_test))))
        print("Classification Report: \n {}\n".format(classification_report(y_test, clf.predict(X_test))))
        print("Confusion Matrix: \n {}\n".format(confusion_matrix(y_test, clf.predict(X_test))))


# In[36]:


print_score(knn, X_train, y_train, X_test, y_test, train=True)


# In[37]:



print_score(knn, X_train, y_train, X_test, y_test, train=False)


# # Grid Search

# In[ ]:




